# PRODIGY_GA_02

This project demonstrates how to use pre-trained generative models—like **Stable Diffusion** to create images from text prompts.

By learning patterns from millions of image–text pairs, these models generate completely new images that match the descriptions you provide.  

**How it works**

- You provide a text prompt describing what you want to see.
- The generative model processes the prompt and uses learned patterns to create a new, unique image.
- The output is an image that visually matches the meaning and style implied by your prompt.

**Libraries used**

- **diffusers** – for loading and running Stable Diffusion or similar models
- **transformers** – for text processing and model support
- **torch** – deep learning backend (PyTorch)

Prompt Used: "A mythical dragon flying around a big castle"

In case you're not able to view the output file, try this link:
https://nbviewer.org/github/sahiltalokar/PRODIGY_GA_02/blob/main/ImageGenerationOutput.ipynb
